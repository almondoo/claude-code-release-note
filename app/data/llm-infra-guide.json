{
  "meta": {
    "title": "エンタープライズLLM基盤の構築ガイド",
    "subtitle": "アーキテクチャ設計から運用まで",
    "date": "2026年2月",
    "audience": "IT・テック企業の技術リーダー・アーキテクト",
    "premise": "全社LLM展開を計画または最適化中の組織向け",
    "keyStats": [
      {
        "label": "アーキテクチャパターン",
        "value": 3,
        "unit": "種類"
      },
      {
        "label": "実装ステップ",
        "value": 48,
        "unit": "手順"
      },
      {
        "label": "コスト削減",
        "value": 90,
        "unit": "%",
        "prefix": "最大"
      },
      {
        "label": "用語解説",
        "value": 66,
        "unit": "語"
      }
    ]
  },
  "sections": [
    {
      "id": "guide-overview",
      "title": "ガイド概要",
      "description": "本ガイドの目的と前提条件",
      "blocks": [
        {
          "type": "text",
          "content": "本ガイドは、企業がLLM基盤を構築・運用するための実践的な手順書です。{{llm-gateway}}の選定からセキュリティ実装、{{finops}}によるコスト最適化まで、エンタープライズLLM基盤に必要な全工程をカバーします。"
        },
        {
          "type": "stats",
          "items": [
            {
              "label": "2025年LLM市場規模",
              "value": "$88億",
              "trend": "up"
            },
            {
              "label": "5+モデル利用企業",
              "value": "37%",
              "trend": "up"
            },
            {
              "label": "キャッシュ効果",
              "value": "最大90%削減",
              "trend": "up"
            },
            {
              "label": "PoC中止率",
              "value": "30%",
              "trend": "down"
            }
          ]
        },
        {
          "type": "highlight",
          "variant": "info",
          "title": "前提条件",
          "content": "本ガイドは、LLM APIの基本的な利用経験があり、全社レベルでのLLM展開を計画または最適化中の組織を対象としています。インフラエンジニアやプラットフォームチームが主な読者です。"
        },
        {
          "type": "list",
          "ordered": true,
          "items": [
            "3つのアーキテクチャパターン（直接利用・GW経由・プライベート）の構築手順",
            "{{dlp}}・{{pii-detection}}・{{rbac}}による多層セキュリティの実装方法",
            "{{prompt-caching}}・{{semantic-caching}}・{{batch-api}}によるコスト最適化",
            "{{observability}}基盤の構築と{{sla}}モニタリングの設定",
            "段階的な導入ロードマップと意思決定フレームワーク"
          ]
        }
      ]
    },
    {
      "id": "architecture-patterns",
      "title": "アーキテクチャパターン",
      "description": "3つの構成パターンの比較と選定基準",
      "blocks": [
        {
          "type": "text",
          "content": "企業のLLM基盤は大きく3つのアーキテクチャパターンに分類できます。組織の規模、セキュリティ要件、予算に応じて最適なパターンを選択し、段階的に進化させていくアプローチが推奨されます。"
        },
        {
          "type": "diagram",
          "data": {
            "variant": "comparison",
            "title": "3つのアーキテクチャパターン比較",
            "caption": "組織の成熟度に応じて段階的にパターンを移行可能",
            "columns": [
              {
                "title": "パターンA: 直接利用",
                "color": "#10B981",
                "items": [
                  "API直接呼び出し",
                  "最小構成・短期導入",
                  "SDK + 環境変数管理",
                  "小〜中規模チーム向け"
                ],
                "footer": "導入: 1-2週間"
              },
              {
                "title": "パターンB: GW経由",
                "color": "#8B5CF6",
                "items": [
                  "プロキシ/GW経由",
                  "一元管理・ガバナンス",
                  "DLP/PII検出統合",
                  "中〜大規模組織向け"
                ],
                "footer": "導入: 4-8週間"
              },
              {
                "title": "パターンC: プライベート",
                "color": "#EC4899",
                "items": [
                  "自社ホスティング",
                  "完全データ統制",
                  "GPU/推論エンジン運用",
                  "規制業界・大規模向け"
                ],
                "footer": "導入: 3-6ヶ月"
              }
            ]
          }
        },
        {
          "type": "table",
          "caption": "パターン別比較マトリクス",
          "headers": [
            "項目",
            "A: 直接利用",
            "B: GW経由",
            "C: プライベート"
          ],
          "rows": [
            [
              "初期コスト",
              "低（$0-1K/月）",
              "中（$2-10K/月）",
              "高（$50K+/月）"
            ],
            [
              "セキュリティ",
              "基本（API鍵管理）",
              "高（DLP/PII/RBAC）",
              "最高（完全隔離）"
            ],
            [
              "運用負荷",
              "最小",
              "中程度",
              "高い"
            ],
            [
              "スケーラビリティ",
              "プロバイダ依存",
              "高い",
              "自社管理"
            ],
            [
              "ベンダーロックイン",
              "高い",
              "低い",
              "なし"
            ],
            [
              "導入期間",
              "1-2週間",
              "4-8週間",
              "3-6ヶ月"
            ]
          ]
        },
        {
          "type": "highlight",
          "variant": "tip",
          "title": "推奨アプローチ",
          "content": "多くの企業では、パターンAで素早く開始し、利用拡大に伴いパターンBへ移行するのが現実的です。規制要件が厳しい業界（金融・医療）ではパターンB/Cの早期検討が必要です。"
        }
      ]
    },
    {
      "id": "pattern-direct",
      "title": "パターンA: 直接利用の構築",
      "description": "API直接呼び出しによる最小構成の実装手順",
      "blocks": [
        {
          "type": "text",
          "content": "最もシンプルなパターンとして、LLM APIを直接呼び出す構成を構築します。{{api-gateway}}を経由せず、アプリケーションから直接プロバイダーAPIにリクエストを送信します。"
        },
        {
          "type": "infraDiagram",
          "variant": "dataflow",
          "title": "パターンA: データフロー",
          "caption": "アプリケーションから直接LLM APIを呼び出すシンプルな構成",
          "stages": [
            {
              "label": "アプリケーション",
              "color": "#10B981",
              "items": [
                "Webアプリ",
                "バッチ処理",
                "CLI ツール"
              ]
            },
            {
              "label": "SDK",
              "color": "#3B82F6",
              "items": [
                "Anthropic SDK",
                "OpenAI SDK"
              ]
            },
            {
              "label": "LLM API",
              "color": "#F59E0B",
              "items": [
                "Claude API",
                "GPT API",
                "Gemini API"
              ]
            },
            {
              "label": "モニタリング",
              "color": "#A855F7",
              "items": [
                "ログ収集",
                "コスト追跡"
              ]
            }
          ]
        },
        {
          "type": "stepGuide",
          "title": "実装ステップ",
          "steps": [
            {
              "label": "Step 1",
              "title": "API鍵の安全な管理",
              "description": "APIキーをシークレット管理サービスで一元管理し、環境変数経由でアプリケーションに注入します。ハードコーディングは厳禁です。",
              "duration": "2-4時間",
              "difficulty": "easy",
              "blocks": [
                {
                  "type": "codeBlock",
                  "language": "bash",
                  "title": "環境変数の設定",
                  "filename": ".env.production",
                  "code": "# シークレット管理サービスから注入\nANTHROPIC_API_KEY=sk-ant-...\nOPENAI_API_KEY=sk-...\n\n# レート制限設定\nLLM_MAX_REQUESTS_PER_MINUTE=60\nLLM_MAX_TOKENS_PER_REQUEST=4096\n\n# フォールバック設定\nLLM_PRIMARY_MODEL=claude-sonnet-4-5-20250929\nLLM_FALLBACK_MODEL=gpt-4o"
                }
              ]
            },
            {
              "label": "Step 2",
              "title": "SDK統合とクライアント実装",
              "description": "Anthropic SDKを使用してLLM呼び出しを実装します。リトライ、タイムアウト、エラーハンドリングを組み込みます。",
              "duration": "4-8時間",
              "difficulty": "easy",
              "blocks": [
                {
                  "type": "codeBlock",
                  "language": "python",
                  "title": "LLMクライアント実装例",
                  "filename": "llm_client.py",
                  "code": "import anthropic\nimport os\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\nclient = anthropic.Anthropic(\n    api_key=os.environ[\"ANTHROPIC_API_KEY\"],\n    max_retries=3,\n    timeout=30.0,\n)\n\n@retry(\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=2, max=10),\n)\ndef call_llm(prompt: str, model: str = \"claude-sonnet-4-5-20250929\") -> str:\n    response = client.messages.create(\n        model=model,\n        max_tokens=4096,\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n    )\n    return response.content[0].text",
                  "caption": "tenacityライブラリでエクスポネンシャルバックオフを実装"
                }
              ]
            },
            {
              "label": "Step 3",
              "title": "レート制限の実装",
              "description": "APIのレート制限を超えないよう、アプリケーション側でリクエストレートを制御します。トークンバケットアルゴリズムが一般的です。",
              "duration": "2-4時間",
              "difficulty": "medium"
            },
            {
              "label": "Step 4",
              "title": "ログ収集とコスト追跡",
              "description": "全てのAPI呼び出しをログに記録し、トークン使用量とコストを追跡します。{{observability}}基盤への統合を検討します。",
              "duration": "4-8時間",
              "difficulty": "medium"
            }
          ]
        },
        {
          "type": "highlight",
          "variant": "warning",
          "title": "直接利用の限界",
          "content": "チーム数が5を超える、月間コストが$5,000を超える、DLP/PII要件がある場合は、パターンBへの移行を検討してください。"
        }
      ]
    },
    {
      "id": "pattern-gateway",
      "title": "パターンB: プロキシ/GWの構築",
      "description": "LLMゲートウェイによる一元管理アーキテクチャ",
      "blocks": [
        {
          "type": "text",
          "content": "{{llm-gateway}}を導入することで、複数チーム・複数モデルの利用を一元管理できます。{{rbac}}、{{dlp}}、{{cost-allocation}}などのエンタープライズ機能を集約し、ガバナンスを強化します。"
        },
        {
          "type": "infraDiagram",
          "variant": "network",
          "title": "パターンB: ネットワーク構成",
          "caption": "LLMゲートウェイがすべてのリクエストを仲介",
          "zones": [
            {
              "label": "クライアント層",
              "color": "#10B981",
              "items": [
                {
                  "label": "Web App",
                  "sublabel": "フロントエンド"
                },
                {
                  "label": "Backend API",
                  "sublabel": "サービス群"
                },
                {
                  "label": "Batch Jobs",
                  "sublabel": "非同期処理"
                }
              ]
            },
            {
              "label": "ゲートウェイ層",
              "color": "#8B5CF6",
              "items": [
                {
                  "label": "LLM Gateway",
                  "sublabel": "リクエスト制御"
                },
                {
                  "label": "DLP/PII",
                  "sublabel": "データ保護"
                },
                {
                  "label": "Cache",
                  "sublabel": "レスポンスキャッシュ"
                }
              ]
            },
            {
              "label": "プロバイダー層",
              "color": "#F59E0B",
              "items": [
                {
                  "label": "Anthropic",
                  "sublabel": "Claude API"
                },
                {
                  "label": "OpenAI",
                  "sublabel": "GPT API"
                },
                {
                  "label": "Google",
                  "sublabel": "Gemini API"
                }
              ]
            },
            {
              "label": "監視・運用層",
              "color": "#A855F7",
              "items": [
                {
                  "label": "Metrics",
                  "sublabel": "Prometheus"
                },
                {
                  "label": "Logs",
                  "sublabel": "Grafana Loki"
                },
                {
                  "label": "Alerts",
                  "sublabel": "PagerDuty"
                }
              ]
            }
          ],
          "connections": [
            {
              "from": "クライアント",
              "to": "ゲートウェイ",
              "label": "HTTPS",
              "style": "solid"
            },
            {
              "from": "ゲートウェイ",
              "to": "プロバイダー",
              "label": "API呼び出し",
              "style": "solid"
            },
            {
              "from": "ゲートウェイ",
              "to": "監視",
              "label": "メトリクス/ログ",
              "style": "dashed"
            }
          ]
        },
        {
          "type": "stepGuide",
          "title": "実装ステップ",
          "steps": [
            {
              "label": "Step 1",
              "title": "ゲートウェイ製品の選定",
              "description": "要件に基づいてLLMゲートウェイを選定します。OSS（LiteLLM Proxy、Portkey）、マネージド（AWS Bedrock、Azure AI Gateway）、専用製品（Helicone、Braintrust）から選択します。",
              "duration": "1-2週間",
              "difficulty": "medium"
            },
            {
              "label": "Step 2",
              "title": "ゲートウェイのデプロイ",
              "description": "選定したゲートウェイを{{kubernetes}}クラスタまたはマネージドサービスにデプロイします。{{vpc}}内に配置してネットワークセキュリティを確保します。",
              "duration": "1-2週間",
              "difficulty": "medium",
              "blocks": [
                {
                  "type": "codeBlock",
                  "language": "yaml",
                  "title": "LiteLLM Proxy のKubernetesデプロイ例",
                  "filename": "litellm-deployment.yaml",
                  "code": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: litellm-proxy\n  namespace: llm-platform\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: litellm-proxy\n  template:\n    metadata:\n      labels:\n        app: litellm-proxy\n    spec:\n      containers:\n        - name: litellm\n          image: ghcr.io/berriai/litellm:main-latest\n          ports:\n            - containerPort: 4000\n          env:\n            - name: ANTHROPIC_API_KEY\n              valueFrom:\n                secretKeyRef:\n                  name: llm-secrets\n                  key: anthropic-api-key\n          resources:\n            requests:\n              cpu: 500m\n              memory: 512Mi\n            limits:\n              cpu: 1000m\n              memory: 1Gi"
                }
              ]
            },
            {
              "label": "Step 3",
              "title": "ルーティングルールの設定",
              "description": "{{smart-routing}}を設定して、リクエストの種類に応じた最適なモデルへの振り分けを自動化します。コスト・品質・レイテンシのバランスを調整します。",
              "duration": "1週間",
              "difficulty": "medium"
            },
            {
              "label": "Step 4",
              "title": "DLP/PIIフィルタの統合",
              "description": "ゲートウェイにDLPフィルタを組み込み、プロンプトに含まれる機密データを自動検出・マスキングします。正規表現とNLPベースの検出を併用します。",
              "duration": "1-2週間",
              "difficulty": "hard"
            },
            {
              "label": "Step 5",
              "title": "キャッシュ層の構築",
              "description": "{{prompt-caching}}と{{semantic-caching}}を設定して、重複リクエストのコストとレイテンシを大幅に削減します。Redis/Valkey をキャッシュバックエンドに使用します。",
              "duration": "1週間",
              "difficulty": "medium"
            }
          ]
        },
        {
          "type": "table",
          "caption": "主要ゲートウェイ製品比較",
          "headers": [
            "製品",
            "タイプ",
            "主な特徴",
            "コスト"
          ],
          "rows": [
            [
              "LiteLLM Proxy",
              "OSS",
              "100+モデル対応、OpenAI互換API",
              "無料（セルフホスト）"
            ],
            [
              "Portkey",
              "マネージド",
              "キャッシュ・フォールバック・ガードレール",
              "$99/月〜"
            ],
            [
              "AWS Bedrock",
              "クラウド",
              "AWS統合、モデルアクセス一元化",
              "従量課金"
            ],
            [
              "Azure AI Gateway",
              "クラウド",
              "APIM統合、エンタープライズSSO",
              "従量課金"
            ],
            [
              "Helicone",
              "マネージド",
              "オブザーバビリティ特化、ワンライン統合",
              "無料枠あり"
            ]
          ]
        }
      ]
    },
    {
      "id": "pattern-private",
      "title": "パターンC: プライベート/オンプレ構築",
      "description": "自社ホスティングによる完全統制アーキテクチャ",
      "blocks": [
        {
          "type": "text",
          "content": "{{zero-data-retention}}を超えてデータの完全統制が求められる場合、{{vllm}}などの{{inference-engine}}を用いてLLMを自社環境にデプロイします。GPU調達とモデル運用の専門知識が前提となります。"
        },
        {
          "type": "infraDiagram",
          "variant": "cloudArch",
          "title": "プライベートLLM基盤構成",
          "provider": "aws",
          "caption": "AWS上での自社ホスティングLLM構成例",
          "layers": [
            {
              "label": "アクセス層",
              "color": "#10B981",
              "services": [
                {
                  "name": "ALB",
                  "description": "ロードバランサー"
                },
                {
                  "name": "API Gateway",
                  "description": "認証・制御"
                }
              ]
            },
            {
              "label": "推論層",
              "color": "#8B5CF6",
              "services": [
                {
                  "name": "vLLM",
                  "description": "推論エンジン"
                },
                {
                  "name": "TGI",
                  "description": "バックアップ"
                },
                {
                  "name": "Triton",
                  "description": "エンベディング"
                }
              ]
            },
            {
              "label": "GPU層",
              "color": "#F59E0B",
              "services": [
                {
                  "name": "p5.48xlarge",
                  "description": "H100 x8"
                },
                {
                  "name": "g5.xlarge",
                  "description": "A10G (小型)"
                }
              ]
            },
            {
              "label": "ストレージ層",
              "color": "#06B6D4",
              "services": [
                {
                  "name": "S3",
                  "description": "モデル保管"
                },
                {
                  "name": "EFS",
                  "description": "共有ストレージ"
                },
                {
                  "name": "ElastiCache",
                  "description": "KVキャッシュ"
                }
              ]
            }
          ]
        },
        {
          "type": "stepGuide",
          "title": "実装ステップ",
          "steps": [
            {
              "label": "Step 1",
              "title": "GPUインフラの調達",
              "description": "ワークロードに応じたGPUインスタンスを選定・確保します。H100 (大型モデル70B+)、A100 (中型モデル)、A10G (小型モデル7B以下) が主な選択肢です。",
              "duration": "2-4週間",
              "difficulty": "hard"
            },
            {
              "label": "Step 2",
              "title": "推論エンジンのデプロイ",
              "description": "{{vllm}}をKubernetesクラスタにデプロイし、モデルのロードと推論サービスを構築します。{{quantization}}でメモリ効率を最適化します。",
              "duration": "1-2週間",
              "difficulty": "hard",
              "blocks": [
                {
                  "type": "codeBlock",
                  "language": "bash",
                  "title": "vLLMの起動コマンド",
                  "code": "# vLLMサーバーの起動 (Llama 3.1 70B, AWQ量子化)\npython -m vllm.entrypoints.openai.api_server \\\n  --model meta-llama/Llama-3.1-70B-Instruct-AWQ \\\n  --quantization awq \\\n  --tensor-parallel-size 4 \\\n  --gpu-memory-utilization 0.9 \\\n  --max-model-len 8192 \\\n  --port 8000 \\\n  --host 0.0.0.0",
                  "caption": "4GPU並列でAWQ量子化モデルをサービング"
                }
              ]
            },
            {
              "label": "Step 3",
              "title": "オートスケーリングの設定",
              "description": "GPUワークロードに応じたカスタムメトリクスベースのオートスケーリングを設定します。Kubernetes HPAとカスタムメトリクスサーバーを使用します。",
              "duration": "1-2週間",
              "difficulty": "hard"
            }
          ]
        },
        {
          "type": "highlight",
          "variant": "warning",
          "title": "コストに注意",
          "content": "H100 x8構成（p5.48xlarge）は約$98/時間。月間フル稼働で$70,000以上になります。GPUの稼働率が50%未満の場合、API利用（パターンA/B）の方がコスト効率が高い可能性があります。"
        }
      ]
    },
    {
      "id": "infra-components",
      "title": "インフラ構成要素",
      "description": "LLM基盤を支える主要コンポーネント",
      "blocks": [
        {
          "type": "text",
          "content": "堅牢なLLM基盤は複数のインフラコンポーネントで構成されます。{{load-balancer}}、キャッシュ層、キューシステム、ストレージの各レイヤーを適切に設計することが重要です。"
        },
        {
          "type": "diagram",
          "data": {
            "variant": "layers",
            "title": "LLM基盤のインフラスタック",
            "caption": "各レイヤーが連携してエンドツーエンドのLLMサービスを提供",
            "layers": [
              {
                "label": "アクセス制御",
                "items": [
                  "SSO/SAML",
                  "RBAC",
                  "APIキー管理",
                  "レート制限"
                ],
                "color": "#EF4444"
              },
              {
                "label": "ゲートウェイ",
                "items": [
                  "ルーティング",
                  "DLP/PII",
                  "ガードレール",
                  "変換"
                ],
                "color": "#8B5CF6"
              },
              {
                "label": "キャッシュ",
                "items": [
                  "プロンプトキャッシュ",
                  "セマンティックキャッシュ",
                  "KVストア"
                ],
                "color": "#3B82F6"
              },
              {
                "label": "キュー/バッチ",
                "items": [
                  "非同期処理",
                  "バッチAPI",
                  "優先度キュー"
                ],
                "color": "#10B981"
              },
              {
                "label": "LLMプロバイダー",
                "items": [
                  "Anthropic",
                  "OpenAI",
                  "Google",
                  "自社モデル"
                ],
                "color": "#F59E0B"
              },
              {
                "label": "監視・ログ",
                "items": [
                  "メトリクス",
                  "トレーシング",
                  "コスト追跡",
                  "アラート"
                ],
                "color": "#A855F7"
              }
            ]
          }
        },
        {
          "type": "subsection",
          "title": "キャッシュ層の設計",
          "blocks": [
            {
              "type": "text",
              "content": "{{prompt-caching}}（完全一致キャッシュ）と{{semantic-caching}}（意味類似キャッシュ）を組み合わせることで、50-90%のコスト削減が見込めます。Redisをバックエンドに使用し、TTLとキャッシュ無効化戦略を設計します。"
            },
            {
              "type": "codeBlock",
              "language": "yaml",
              "title": "Redisキャッシュ設定例",
              "filename": "cache-config.yaml",
              "code": "cache:\n  backend: redis\n  redis_url: redis://cache.internal:6379/0\n  \n  # 完全一致キャッシュ\n  exact_match:\n    enabled: true\n    ttl: 3600  # 1時間\n    max_entries: 100000\n  \n  # セマンティックキャッシュ\n  semantic:\n    enabled: true\n    similarity_threshold: 0.95\n    embedding_model: text-embedding-3-small\n    ttl: 7200  # 2時間\n    max_entries: 50000"
            }
          ]
        },
        {
          "type": "subsection",
          "title": "キューとバッチ処理",
          "blocks": [
            {
              "type": "text",
              "content": "リアルタイム性が不要なワークロードは{{batch-api}}を活用して50%のコスト削減が可能です。SQSやRabbitMQを使用した非同期処理パイプラインを構築し、優先度に基づいたキュー管理を実装します。"
            }
          ]
        }
      ]
    },
    {
      "id": "security-overview",
      "title": "セキュリティ概要",
      "description": "LLM基盤におけるセキュリティアーキテクチャの全体像",
      "blocks": [
        {
          "type": "text",
          "content": "LLMシステムは従来のWebアプリケーションとは異なるセキュリティ特性を持ちます。自然言語インタフェースを介した攻撃（{{prompt-injection}}）、学習データ経由の情報漏洩、非決定的な出力に対する検証の困難さなど、従来のセキュリティフレームワークだけでは対処できない固有のリスクが存在します。OWASP Top 10 for LLM Applications（2025）やMITRE ATLASが示すように、LLM特有の脅威モデルを理解したうえで、{{guardrails}}・{{dlp}}・{{zero-trust}}を組み合わせた多層防御の設計が求められます。"
        },
        {
          "type": "stats",
          "items": [
            {
              "label": "防御領域",
              "value": "6つ",
              "trend": "neutral"
            },
            {
              "label": "OWASP LLM Top 10",
              "value": "2025版",
              "trend": "neutral"
            },
            {
              "label": "対応パターン",
              "value": "3種類",
              "trend": "neutral"
            },
            {
              "label": "インフラ構成図",
              "value": "5つ",
              "trend": "neutral"
            }
          ]
        },
        {
          "type": "table",
          "caption": "統合セキュリティチェックリスト（フェーズ別優先度）",
          "headers": [
            "領域",
            "項目",
            "初期構築",
            "運用安定期",
            "成熟期"
          ],
          "rows": [
            [
              "データ保護",
              "PII検出・マスキングの実装",
              "◎ 必須",
              "◎",
              "◎"
            ],
            [
              "データ保護",
              "データ分類ポリシーの策定と適用",
              "◎ 必須",
              "◎",
              "◎"
            ],
            [
              "データ保護",
              "DLPの継続的チューニング",
              "○ 推奨",
              "◎ 必須",
              "◎"
            ],
            [
              "アクセス制御",
              "RBAC/ABACの実装",
              "◎ 必須",
              "◎",
              "◎"
            ],
            [
              "アクセス制御",
              "APIキーの自動ローテーション",
              "○ 推奨",
              "◎ 必須",
              "◎"
            ],
            [
              "アクセス制御",
              "SSO/IdP統合",
              "○ 推奨",
              "◎ 必須",
              "◎"
            ],
            [
              "ネットワーク",
              "TLS 1.3の全通信適用",
              "◎ 必須",
              "◎",
              "◎"
            ],
            [
              "ネットワーク",
              "Private Link / VPC Endpoint",
              "○ 推奨",
              "◎ 必須",
              "◎"
            ],
            [
              "ネットワーク",
              "ゼロトラスト（IAP + mTLS）",
              "△ 検討",
              "○ 推奨",
              "◎ 必須"
            ],
            [
              "プロンプト",
              "入出力ガードレール",
              "◎ 必須",
              "◎",
              "◎"
            ],
            [
              "プロンプト",
              "Prompt Injection分類器",
              "○ 推奨",
              "◎ 必須",
              "◎"
            ],
            [
              "プロンプト",
              "定期的なレッドチームテスト",
              "△ 検討",
              "○ 推奨",
              "◎ 必須"
            ],
            [
              "コンプライアンス",
              "監査ログの取得・保管",
              "◎ 必須",
              "◎",
              "◎"
            ],
            [
              "コンプライアンス",
              "規制対応の文書化",
              "◎ 必須",
              "◎",
              "◎"
            ],
            [
              "コンプライアンス",
              "リアルタイム異常検知",
              "△ 検討",
              "○ 推奨",
              "◎ 必須"
            ],
            [
              "サプライチェーン",
              "プロバイダー信頼性評価",
              "◎ 必須",
              "◎",
              "◎"
            ],
            [
              "サプライチェーン",
              "モデル整合性検証",
              "○ 推奨",
              "◎ 必須",
              "◎"
            ],
            [
              "サプライチェーン",
              "MCPサーバー/プラグインのサンドボックス",
              "△ 検討",
              "○ 推奨",
              "◎ 必須"
            ]
          ],
          "footnote": "◎ 必須 = 対応必須 | ○ 推奨 = 対応を強く推奨 | △ 検討 = リスク評価に基づき検討"
        },
        {
          "type": "table",
          "caption": "パターン選定ガイド（セキュリティ観点）",
          "headers": [
            "判断基準",
            "パターンA（直接利用）",
            "パターンB（GW経由）",
            "パターンC（プライベート）"
          ],
          "rows": [
            [
              "組織規模",
              "〜50名",
              "50〜5,000名",
              "規模問わず（規制要件駆動）"
            ],
            [
              "月間LLMコスト",
              "〜$5,000",
              "$5,000〜$100,000",
              "$100,000+（GPU含む）"
            ],
            [
              "データ機密度",
              "Public / Internal",
              "Internal / Confidential",
              "Confidential / Restricted"
            ],
            [
              "規制要件",
              "低（一般IT企業）",
              "中（個人情報保護法）",
              "高（金融 / 医療 / 防衛）"
            ],
            [
              "運用チーム",
              "兼任1-2名",
              "専任2-5名",
              "専任5名以上"
            ],
            [
              "導入期間",
              "1-2週間",
              "1-3ヶ月",
              "3-12ヶ月"
            ],
            [
              "初期投資",
              "低",
              "中",
              "高"
            ]
          ]
        },
        {
          "type": "highlight",
          "variant": "info",
          "title": "対象読者と前提条件",
          "content": "本セキュリティガイドは、LLM APIの基本的な利用経験があるインフラエンジニア・プラットフォームチーム・技術リーダーを対象としています。3つのアーキテクチャパターン（A: API直接利用、B: LLMゲートウェイ/プロキシ経由、C: プライベート/オンプレミスホスティング）それぞれに対する具体的なセキュリティ設計指針を提示します。"
        },
        {
          "type": "reactFlowDiagram",
          "diagramId": "aws-security"
        }
      ]
    },
    {
      "id": "security-data-protection",
      "title": "データ保護・プライバシー",
      "description": "LLMプロンプトの機密情報検出とデータ分類",
      "blocks": [
        {
          "type": "text",
          "content": "LLMへのプロンプトには、意図的・非意図的に機密情報が含まれるリスクがあります。Samsung社員がChatGPTにソースコードを入力したインシデント（2023年）は、LLM利用におけるデータ漏洩の代表的事例です。また、LLMの出力にも学習データに含まれていた個人情報やAPIキーが再現されるリスクがあります。従来の{{dlp}}ソリューションはHTTPペイロードの定型パターンを検出対象としていましたが、自然言語に埋め込まれた機密情報の検出には{{ner}}を活用した新たなアプローチが必要です。"
        },
        {
          "type": "list",
          "ordered": false,
          "items": [
            "**最小情報原則**: LLMに送信するデータは必要最小限に留める",
            "**多層検出**: 正規表現による高速パターンマッチとNER（{{ner}}）モデルによる文脈理解を組み合わせる",
            "**機密レベル連動**: {{data-classification}}ポリシーに基づき、機密度に応じてLLM利用を制限する",
            "**検出と透明性のバランス**: 誤検知によるユーザー体験の低下を防ぎつつ、高リスクの漏洩は確実にブロックする"
          ]
        },
        {
          "type": "table",
          "caption": "DLPツール比較",
          "headers": [
            "手法",
            "ツール/サービス",
            "特徴",
            "適用フェーズ"
          ],
          "rows": [
            [
              "正規表現パターンマッチ",
              "カスタム実装 / AWS Macie",
              "クレジットカード番号、マイナンバー、電話番号等の定型パターンを高速検出。低レイテンシだが文脈理解に限界あり",
              "入力/出力"
            ],
            [
              "NERモデル",
              "Microsoft Presidio / spaCy / GiNZA",
              "人名・組織名・住所等の非定型PIIを文脈から検出。日本語対応にはGiNZAやMeCab辞書との統合が効果的",
              "入力/出力"
            ],
            [
              "クラウドDLPサービス",
              "Google Cloud DLP / AWS Comprehend",
              "マネージドサービスとして150+の情報タイプを検出。API呼び出し型でスケーラブル",
              "入力/出力"
            ],
            [
              "LLMゲートウェイ統合DLP",
              "Portkey / LiteLLM / Guardrails AI",
              "LLMプロキシに組み込まれたDLP。プロンプト/レスポンスの中間で透過的に処理",
              "入力/出力"
            ]
          ]
        },
        {
          "type": "codeBlock",
          "language": "python",
          "title": "Presidio PII検出・匿名化",
          "filename": "pii_sanitizer.py",
          "code": "from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\nfrom presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import OperatorConfig\n\n# 日本語対応のためカスタムRecognizerを登録\nregistry = RecognizerRegistry()\nregistry.load_predefined_recognizers(languages=[\"en\", \"ja\"])\n\nanalyzer = AnalyzerEngine(registry=registry)\nanonymizer = AnonymizerEngine()\n\ndef sanitize_prompt(text: str) -> str:\n    \"\"\"プロンプト送信前のPII検出・マスキング\"\"\"\n    results = analyzer.analyze(\n        text=text,\n        language=\"ja\",\n        entities=[\"PERSON\", \"PHONE_NUMBER\", \"EMAIL_ADDRESS\",\n                  \"CREDIT_CARD\", \"JP_MY_NUMBER\"]\n    )\n    anonymized = anonymizer.anonymize(\n        text=text,\n        analyzer_results=results,\n        operators={\n            \"PERSON\": OperatorConfig(\"replace\", {\"new_value\": \"[氏名]\"}),\n            \"PHONE_NUMBER\": OperatorConfig(\"mask\", {\n                \"chars_to_mask\": 8,\n                \"masking_char\": \"*\",\n                \"from_end\": False\n            }),\n            \"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED]\"})\n        }\n    )\n    return anonymized.text",
          "caption": "本番環境ではGiNZA（日本語NER）との統合により検出精度を向上"
        },
        {
          "type": "table",
          "caption": "データ分類ポリシー",
          "headers": [
            "分類レベル",
            "定義",
            "LLM利用制限",
            "例"
          ],
          "rows": [
            [
              "Public",
              "公開情報",
              "制限なし（外部APIへの送信可）",
              "公開ドキュメント、マーケティング資料"
            ],
            [
              "Internal",
              "社内限定情報",
              "外部API利用可（DLPチェック必須）",
              "社内Wiki、議事録"
            ],
            [
              "Confidential",
              "機密情報",
              "ゲートウェイ経由のみ（PII匿名化必須）",
              "顧客データ、契約書"
            ],
            [
              "Restricted",
              "最高機密",
              "プライベートモデルのみ / LLM利用禁止",
              "暗号鍵、医療データ、特許出願前の技術情報"
            ]
          ]
        },
        {
          "type": "subsection",
          "title": "パターン別推奨構成",
          "blocks": [
            {
              "type": "list",
              "ordered": false,
              "items": [
                "**パターンA（API直接利用）**: クライアントサイドでPresidio等を用いたPII検出を実装。CI/CDパイプラインにDLPスキャンを組み込み、APIキーやシークレットの送信を防止",
                "**パターンB（ゲートウェイ経由）**: LLMゲートウェイにDLPミドルウェアを配置し、全リクエスト/レスポンスを透過的に検査。{{data-classification}}ポリシーとの連動によりConfidential以上のデータを自動ブロック",
                "**パターンC（プライベートホスティング）**: データがネットワーク外に出ないためリスクは低減するが、内部者脅威への対策としてDLPは依然必要。推論サーバー前段にDLPプロキシを配置"
              ]
            }
          ]
        },
        {
          "type": "checklist",
          "categories": [
            {
              "name": "データ保護チェックリスト",
              "items": [
                "プロンプト送信前のPII検出・マスキング機構が実装されている",
                "レスポンスに対する機密情報フィルタが実装されている",
                "データ分類ポリシーが定義され、分類レベルに応じたLLM利用制限が実装されている",
                "日本語PIIの検出精度テストが実施されている（マイナンバー、氏名、住所等）",
                "DLP検出ルールの定期的な更新・チューニングのプロセスが確立されている",
                "誤検知率（False Positive）の監視とフィードバックループが構築されている",
                "APIプロバイダーのデータ利用ポリシー（学習への使用有無）を確認・合意している",
                "DLPログが監査要件を満たす形で保持されている"
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "security-access-control",
      "title": "アクセス制御・認証",
      "description": "RBAC/ABACによるLLMアクセスの精緻な制御",
      "blocks": [
        {
          "type": "text",
          "content": "LLMへのアクセスは「誰が」「どのモデルに」「どのような操作を」行えるかの精緻な制御が必要です。単一のAPIキーを複数チームで共有する運用は、{{audit-log}}追跡の困難さと不正利用時の影響範囲拡大を招きます。また、LLMのツール利用（Function Calling / MCP）における権限昇格のリスクは新たな攻撃面となっています。{{rbac}}に加え、{{abac}}を組み合わせた柔軟なアクセス制御と、{{opa}}によるポリシーエンジンの導入が推奨されます。"
        },
        {
          "type": "list",
          "ordered": false,
          "items": [
            "**最小権限の原則**: ユーザー・サービスアカウントに対し、必要最小限のモデル・機能へのアクセスのみを付与",
            "**認証の一元化**: 企業IdP（Identity Provider）との統合により、既存のID管理基盤を活用",
            "**短命クレデンシャル**: 長期APIキーではなく、有効期限付きトークンと自動ローテーションを基本とする",
            "**ゼロトラスト**: すべてのリクエストを検証し、暗黙の信頼を排除する"
          ]
        },
        {
          "type": "table",
          "caption": "RBACロールマトリクス",
          "headers": [
            "ロール",
            "許可モデル",
            "機能制限",
            "レート制限"
          ],
          "rows": [
            [
              "developer",
              "GPT-4o, Claude Sonnet",
              "テキスト生成、コード補完",
              "100 req/min"
            ],
            [
              "analyst",
              "GPT-4o, Gemini Pro",
              "テキスト生成、RAG検索",
              "50 req/min"
            ],
            [
              "admin",
              "全モデル",
              "全機能 + ツール利用",
              "200 req/min"
            ],
            [
              "service-account",
              "指定モデルのみ",
              "バッチ処理、パイプライン統合",
              "500 req/min"
            ]
          ]
        },
        {
          "type": "codeBlock",
          "language": "rego",
          "title": "OPA ABACポリシー",
          "filename": "llm_authz.rego",
          "code": "package llm.authz\n\ndefault allow = false\n\nallow {\n    input.user.role == \"developer\"\n    input.model in {\"gpt-4o\", \"claude-sonnet-4-5\"}\n    input.data_classification in {\"public\", \"internal\"}\n    input.source_network == \"vpn\"\n}\n\nallow {\n    input.user.role == \"admin\"\n    input.source_network in {\"vpn\", \"office\"}\n}\n\n# ツール利用（Function Calling）の制限\nallow_tool_use {\n    input.user.role == \"admin\"\n    input.tool_name in allowed_tools[input.user.department]\n}\n\nallowed_tools[\"engineering\"] = {\"code_interpreter\", \"file_search\"}\nallowed_tools[\"legal\"] = {\"document_search\"}",
          "caption": "Regoでポリシーをコード化し、GitOpsで管理・デプロイする"
        },
        {
          "type": "table",
          "caption": "API鍵管理要件",
          "headers": [
            "要件",
            "実装方法",
            "ツール"
          ],
          "rows": [
            [
              "安全な保管",
              "暗号化されたシークレットストアに格納。環境変数や設定ファイルへの直書きを禁止",
              "HashiCorp Vault, AWS Secrets Manager, Azure Key Vault"
            ],
            [
              "自動ローテーション",
              "30〜90日周期でのキーローテーション。Vaultのdynamic secretsを利用",
              "Vault Dynamic Secrets, AWS Lambda + Secrets Manager"
            ],
            [
              "アクセス監査",
              "シークレットへのアクセスログを記録し、異常なアクセスパターンを検出",
              "Vault Audit Log, CloudTrail"
            ],
            [
              "スコープ制限",
              "APIキーにサービスアカウント・IPレンジ・利用制限を紐付け",
              "プロバイダーAPI設定 + ゲートウェイポリシー"
            ]
          ]
        },
        {
          "type": "codeBlock",
          "language": "yaml",
          "title": "Vault Agent Injector + Istio mTLS",
          "filename": "llm-gateway-deployment.yaml",
          "code": "# Kubernetes連携 (Vault Agent Injector)\n# Pod起動時にVaultからシークレットを自動注入\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: llm-gateway\nspec:\n  template:\n    metadata:\n      annotations:\n        vault.hashicorp.com/agent-inject: \"true\"\n        vault.hashicorp.com/agent-inject-secret-openai: \"secret/data/llm/openai\"\n        vault.hashicorp.com/role: \"llm-gateway\"\n---\n# Istio PeerAuthentication によるmTLS強制\napiVersion: security.istio.io/v1\nkind: PeerAuthentication\nmetadata:\n  name: llm-namespace-mtls\n  namespace: llm-platform\nspec:\n  mtls:\n    mode: STRICT  # mTLS必須、証明書なしでは接続拒否",
          "caption": "Vaultによるシークレット管理とIstioによるmTLS通信の組み合わせ"
        },
        {
          "type": "subsection",
          "title": "パターン別推奨構成",
          "blocks": [
            {
              "type": "list",
              "ordered": false,
              "items": [
                "**パターンA（API直接利用）**: Secrets Manager + 環境変数注入によるAPIキー管理。チームごとに個別のAPIキーを発行し、利用量の追跡と制限を実施",
                "**パターンB（ゲートウェイ経由）**: ゲートウェイでOIDC/SAMLトークンを検証し、ユーザー属性に基づく{{abac}}を実行。バックエンドAPIキーはゲートウェイのみが保持",
                "**パターンC（プライベートホスティング）**: Kubernetes RBAC + Istio AuthorizationPolicyによる多層アクセス制御。{{mtls}}を推論エンドポイントまで徹底"
              ]
            }
          ]
        },
        {
          "type": "checklist",
          "categories": [
            {
              "name": "アクセス制御チェックリスト",
              "items": [
                "モデル・機能単位のRBAC/ABACポリシーが定義・実装されている",
                "全APIキーがシークレットストアで管理され、自動ローテーションが有効である",
                "APIキーのハードコーディング検出がCI/CDに組み込まれている（gitleaks等）",
                "企業IdPとのSSO統合が完了し、LLMアクセスが一元管理されている",
                "サービス間通信にmTLSが適用されている",
                "ツール利用（Function Calling / MCP）に対する個別の認可ポリシーが定義されている",
                "定期的なアクセス権レビュー（棚卸し）のプロセスが確立されている"
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "security-network",
      "title": "ネットワークセキュリティ",
      "description": "プライベート接続とゼロトラストの実装",
      "blocks": [
        {
          "type": "text",
          "content": "LLM APIへの通信は機密性の高いプロンプトとレスポンスを含むため、通信経路のセキュリティが極めて重要です。パブリックインターネット経由のAPI呼び出しは盗聴リスクがあり、TLS暗号化だけでは不十分な場合があります。さらに、LLMのエージェント機能（ツール利用、外部API呼び出し）が普及するにつれ、{{egress-control}}が新たな課題となっています。{{private-link}}と{{zero-trust}}を組み合わせた多層防御が推奨されます。"
        },
        {
          "type": "list",
          "ordered": false,
          "items": [
            "**プライベート接続の優先**: 可能な限りパブリックインターネットを経由しない接続経路を選択する",
            "**多層防御**: ネットワーク層、トランスポート層、アプリケーション層の各レベルでセキュリティ制御を実装",
            "**{{zero-trust}}**: ネットワーク位置に基づく暗黙の信頼を排除し、すべてのアクセスを検証する",
            "**最小通信原則**: 必要な通信のみを許可し、不要なEgressを遮断する"
          ]
        },
        {
          "type": "table",
          "caption": "Private Link比較（AWS/Azure/GCP）",
          "headers": [
            "クラウド",
            "サービス",
            "LLM対応",
            "構成概要"
          ],
          "rows": [
            [
              "AWS",
              "PrivateLink + VPC Endpoint",
              "Bedrock (VPC Endpoint対応)",
              "VPCエンドポイントを作成し、Bedrockへの通信をAWSバックボーン内に閉じる"
            ],
            [
              "Azure",
              "Private Endpoint",
              "Azure OpenAI (Private Endpoint対応)",
              "Private EndpointでプライベートIP経由アクセスを確立。パブリックアクセスを無効化"
            ],
            [
              "GCP",
              "Private Service Connect",
              "Vertex AI (VPC-SC対応)",
              "Private Service Connectエンドポイントを作成。VPC-SCによりデータ持ち出しも制御"
            ]
          ]
        },
        {
          "type": "codeBlock",
          "language": "hcl",
          "title": "AWS PrivateLink Terraform",
          "filename": "bedrock-vpc-endpoint.tf",
          "code": "resource \"aws_vpc_endpoint\" \"bedrock\" {\n  vpc_id              = aws_vpc.main.id\n  service_name        = \"com.amazonaws.ap-northeast-1.bedrock-runtime\"\n  vpc_endpoint_type   = \"Interface\"\n  subnet_ids          = aws_subnet.private[*].id\n  security_group_ids  = [aws_security_group.bedrock_endpoint.id]\n  private_dns_enabled = true  # プライベートDNSで名前解決\n\n  tags = { Name = \"bedrock-vpc-endpoint\" }\n}\n\nresource \"aws_security_group\" \"bedrock_endpoint\" {\n  vpc_id = aws_vpc.main.id\n  ingress {\n    from_port       = 443\n    to_port         = 443\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.llm_gateway.id]\n  }\n}",
          "caption": "ゲートウェイからのみVPCエンドポイントへのアクセスを許可するSG設計"
        },
        {
          "type": "table",
          "caption": "WAF/API Gateway制御一覧",
          "headers": [
            "制御",
            "実装",
            "目的"
          ],
          "rows": [
            [
              "レート制限",
              "API Gateway throttling（ユーザー/APIキー単位）",
              "DoS攻撃防御、コスト制御"
            ],
            [
              "ペイロードサイズ制限",
              "API Gateway: max 10MB、WAFルールでbody size検査",
              "リソース枯渇防止"
            ],
            [
              "IPフィルタリング",
              "WAF IP Sets / Security Group",
              "許可IPレンジからのアクセスのみ許可"
            ],
            [
              "地理的制限",
              "WAF Geo-match",
              "特定リージョンからのアクセスブロック"
            ],
            [
              "異常検知",
              "AWS WAF Bot Control / カスタムルール",
              "異常なリクエストパターンの検出"
            ]
          ]
        },
        {
          "type": "text",
          "content": "**ゼロトラストアーキテクチャ**: LLM通信経路に{{zero-trust}}を適用する場合、信頼境界はリクエストの「各ホップ」に設定します。BeyondCorp / ZTNAの考え方に基づき、{{iap}}（Google IAP / Azure AD Application Proxy / Cloudflare Access）をLLMゲートウェイの前段に配置し、ユーザー認証とデバイスポスチャーチェックを行ったうえでアクセスを許可する構成が推奨されます。"
        },
        {
          "type": "codeBlock",
          "language": "yaml",
          "title": "K8s NetworkPolicy（Egress制御）",
          "filename": "llm-agent-egress.yaml",
          "code": "apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: llm-agent-egress\n  namespace: llm-platform\nspec:\n  podSelector:\n    matchLabels:\n      app: llm-agent\n  policyTypes:\n    - Egress\n  egress:\n    # 許可: LLM API (PrivateLink経由)\n    - to:\n        - ipBlock:\n            cidr: 10.0.100.0/24  # VPC Endpointのサブネット\n      ports:\n        - port: 443\n          protocol: TCP\n    # 許可: 社内APIのみ\n    - to:\n        - namespaceSelector:\n            matchLabels:\n              name: internal-apis\n      ports:\n        - port: 443\n          protocol: TCP\n    # DNS\n    - to: []\n      ports:\n        - port: 53\n          protocol: UDP",
          "caption": "LLMエージェントの外部通信をホワイトリスト方式で厳密に制御"
        },
        {
          "type": "infraDiagram",
          "variant": "cloudArch",
          "title": "AWS LLMセキュリティアーキテクチャ",
          "caption": "VPC設計とセキュリティレイヤーの配置。全トラフィックがPrivate Subnet内のLLMゲートウェイを経由する構成",
          "provider": "aws",
          "layers": [
            {
              "label": "Public Subnet",
              "color": "#FEF3C7",
              "services": [
                {
                  "name": "ALB",
                  "description": "Application Load Balancer"
                },
                {
                  "name": "AWS WAF",
                  "description": "レート制限 / ペイロード検査 / Geo制限"
                }
              ]
            },
            {
              "label": "Private Subnet (Application)",
              "color": "#DBEAFE",
              "services": [
                {
                  "name": "API Gateway",
                  "description": "REST / HTTP"
                },
                {
                  "name": "Lambda Authorizer",
                  "description": "JWT検証 / RBAC・ABACチェック / OPA評価"
                },
                {
                  "name": "LLM Gateway",
                  "description": "Portkey / LiteLLM / Custom"
                },
                {
                  "name": "DLP Engine",
                  "description": "PII検出 / 機密情報マスキング"
                },
                {
                  "name": "入力ガードレール",
                  "description": "Prompt Injection検出 / ブロックリスト"
                },
                {
                  "name": "出力ガードレール",
                  "description": "有害コンテンツ検出 / スキーマ検証"
                }
              ]
            },
            {
              "label": "Private Subnet (Data)",
              "color": "#FCE7F3",
              "services": [
                {
                  "name": "Secrets Manager",
                  "description": "APIキー管理"
                },
                {
                  "name": "KMS",
                  "description": "暗号化キー管理"
                },
                {
                  "name": "S3",
                  "description": "監査ログ保管（KMS暗号化）"
                },
                {
                  "name": "OpenSearch",
                  "description": "ログ検索・分析"
                }
              ]
            },
            {
              "label": "LLM Providers (PrivateLink)",
              "color": "#D1FAE5",
              "services": [
                {
                  "name": "AWS Bedrock",
                  "description": "Claude / Titan"
                },
                {
                  "name": "外部API",
                  "description": "OpenAI / Anthropic（PrivateLink経由）"
                }
              ]
            }
          ]
        },
        {
          "type": "infraDiagram",
          "variant": "network",
          "title": "ゼロトラスト LLMネットワーク構成",
          "caption": "Identity-Aware Proxy、Istio mTLS、マイクロセグメンテーションを適用した構成",
          "zones": [
            {
              "label": "External Trust Boundary",
              "color": "#FEE2E2",
              "items": [
                {
                  "label": "ユーザー",
                  "sublabel": "デバイス（MDM管理）"
                }
              ]
            },
            {
              "label": "Edge Trust Boundary",
              "color": "#FEF3C7",
              "items": [
                {
                  "label": "Identity-Aware Proxy",
                  "sublabel": "デバイスポスチャー / OIDC認証 / コンテキスト判定"
                }
              ]
            },
            {
              "label": "llm-gateway (mTLS STRICT)",
              "color": "#DBEAFE",
              "items": [
                {
                  "label": "LLM Gateway"
                }
              ]
            },
            {
              "label": "llm-security (mTLS STRICT)",
              "color": "#EDE9FE",
              "items": [
                {
                  "label": "DLP / Guardrails",
                  "sublabel": "PII検出 / Prompt検証"
                }
              ]
            },
            {
              "label": "llm-inference (mTLS STRICT)",
              "color": "#D1FAE5",
              "items": [
                {
                  "label": "推論サーバー",
                  "sublabel": "vLLM / TGI"
                }
              ]
            },
            {
              "label": "llm-tools (mTLS STRICT)",
              "color": "#FCE7F3",
              "items": [
                {
                  "label": "ツール実行サンドボックス",
                  "sublabel": "Egress制限 / ReadOnly FS"
                }
              ]
            }
          ],
          "connections": [
            {
              "from": "ユーザー",
              "to": "Identity-Aware Proxy",
              "label": "TLS 1.3",
              "style": "solid"
            },
            {
              "from": "Identity-Aware Proxy",
              "to": "LLM Gateway",
              "label": "JWT付与",
              "style": "solid"
            },
            {
              "from": "LLM Gateway",
              "to": "DLP / Guardrails",
              "label": "mTLS",
              "style": "solid"
            },
            {
              "from": "DLP / Guardrails",
              "to": "推論サーバー",
              "label": "mTLS",
              "style": "solid"
            },
            {
              "from": "推論サーバー",
              "to": "ツール実行サンドボックス",
              "label": "mTLS",
              "style": "dashed"
            }
          ]
        },
        {
          "type": "infraDiagram",
          "variant": "network",
          "title": "マルチクラウド/ハイブリッド構成",
          "caption": "オンプレミスのプライベートモデルとクラウドの商用APIを併用する構成",
          "zones": [
            {
              "label": "オンプレミス データセンター",
              "color": "#E0E7FF",
              "items": [
                {
                  "label": "プライベートモデル",
                  "sublabel": "Llama / Mistral (GPU: H100×8)"
                },
                {
                  "label": "推論サーバー",
                  "sublabel": "vLLM + TGI"
                },
                {
                  "label": "オンプレミス GW",
                  "sublabel": "ローカルDLP / キャッシュ"
                }
              ]
            },
            {
              "label": "統一 LLM ゲートウェイ",
              "color": "#FEF3C7",
              "items": [
                {
                  "label": "リクエストルーター",
                  "sublabel": "データ分類に基づくルーティング"
                },
                {
                  "label": "ポリシーエンジン (OPA)"
                },
                {
                  "label": "統一DLPレイヤー"
                },
                {
                  "label": "セマンティックキャッシュ",
                  "sublabel": "Redis + Embedding"
                }
              ]
            },
            {
              "label": "クラウドプロバイダー",
              "color": "#D1FAE5",
              "items": [
                {
                  "label": "AWS Bedrock",
                  "sublabel": "ap-northeast-1"
                },
                {
                  "label": "Azure OpenAI",
                  "sublabel": "Japan East"
                },
                {
                  "label": "GCP Vertex AI",
                  "sublabel": "asia-northeast1"
                }
              ]
            }
          ],
          "connections": [
            {
              "from": "リクエストルーター",
              "to": "ポリシーエンジン (OPA)",
              "label": "ポリシー評価",
              "style": "solid"
            },
            {
              "from": "統一DLPレイヤー",
              "to": "オンプレミス GW",
              "label": "Restricted データ",
              "style": "solid"
            },
            {
              "from": "統一DLPレイヤー",
              "to": "AWS Bedrock",
              "label": "Confidential（日本）",
              "style": "dashed"
            },
            {
              "from": "統一DLPレイヤー",
              "to": "Azure OpenAI",
              "label": "Confidential（日本）",
              "style": "dashed"
            },
            {
              "from": "統一DLPレイヤー",
              "to": "GCP Vertex AI",
              "label": "Internal データ",
              "style": "dashed"
            }
          ]
        },
        {
          "type": "subsection",
          "title": "パターン別推奨構成",
          "blocks": [
            {
              "type": "list",
              "ordered": false,
              "items": [
                "**パターンA（API直接利用）**: TLS 1.3必須。可能であれば{{private-link}}利用。{{egress-control}}はファイアウォール/プロキシで許可ドメインをホワイトリスト化",
                "**パターンB（ゲートウェイ経由）**: WAF → API Gateway → Lambda Authorizer → LLM Gatewayの多層構成。Private Link経由でLLM APIに接続。Private Subnet + NLBで構成",
                "**パターンC（プライベートホスティング）**: 完全にVPC内で完結。推論サーバーはPrivate Subnetに配置し外部通信を一切遮断。Istio STRICT {{mtls}}で全通信を暗号化・認証"
              ]
            }
          ]
        },
        {
          "type": "checklist",
          "categories": [
            {
              "name": "ネットワークセキュリティチェックリスト",
              "items": [
                "LLM APIへの接続がPrivate Link / Private Endpoint経由で構成されている",
                "TLS 1.3が全通信経路で適用されている",
                "WAF / API Gatewayによるレート制限・ペイロード検査が有効化されている",
                "ゼロトラスト原則に基づき、全リクエストの認証・認可が実装されている",
                "LLMエージェントのEgress通信がホワイトリストで制限されている",
                "ネットワークフローログが取得・監視されている",
                "マイクロセグメンテーションにより不要な通信が遮断されている"
              ]
            }
          ]
        },
        {
          "type": "reactFlowDiagram",
          "diagramId": "zero-trust"
        },
        {
          "type": "reactFlowDiagram",
          "diagramId": "multi-cloud"
        }
      ]
    },
    {
      "id": "security-prompt",
      "title": "プロンプトセキュリティ",
      "description": "Prompt Injection対策とガードレール実装",
      "blocks": [
        {
          "type": "text",
          "content": "{{prompt-injection}}は、LLMアプリケーション固有の攻撃ベクトルであり、OWASP Top 10 for LLM Applications（2025）において最上位にランクされています。直接的インジェクション（ユーザーが攻撃コードを直接入力）と間接的インジェクション（外部データソースに仕込まれた攻撃コードをLLMが処理）の2種類があり、後者はRAGやツール利用の普及に伴い特に深刻な脅威となっています。"
        },
        {
          "type": "highlight",
          "variant": "warning",
          "title": "間接Prompt Injectionの実例",
          "content": "間接的Prompt Injectionにより、LLMチャットボットがユーザーの個人情報を攻撃者のサーバーに送信する事例が報告されています。Webページやメール本文に埋め込まれた不可視の指示文が、RAGを通じてLLMに読み込まれ、意図しない動作を引き起こすパターンが主流です。"
        },
        {
          "type": "list",
          "ordered": false,
          "items": [
            "**多層防御**: 入力側・処理層・出力側の各レベルで{{guardrails}}を実装する",
            "**信頼境界の明確化**: システムプロンプト（信頼）とユーザー入力（非信頼）を明確に分離する",
            "**最小権限**: LLMに与えるツール・データアクセスを必要最小限に制限する",
            "**検出と緩和の併用**: 完全な防御は困難であるため、検出・ログ記録・アラートによる早期発見と緩和策を組み合わせる"
          ]
        },
        {
          "type": "table",
          "caption": "Prompt Injection対策5層",
          "headers": [
            "対策層",
            "手法",
            "ツール/実装"
          ],
          "rows": [
            [
              "入力検証",
              "パターンマッチによる攻撃シグネチャの検出",
              "ブロックリスト（\"ignore previous instructions\"等）、正規表現フィルタ"
            ],
            [
              "入力分類",
              "ML分類器による攻撃プロンプトの検出",
              "Rebuff、Lakera Guard、NVIDIA NeMo Guardrails、Protect AI Guardian"
            ],
            [
              "プロンプト設計",
              "システムプロンプトでの防御指示、デリミタによる分離",
              "XML/JSONタグによるコンテキスト分離、防御プロンプトの埋め込み"
            ],
            [
              "サンドボックス",
              "構造化された出力のみを処理",
              "出力をJSONスキーマで制約、Function Calling結果を検証後に実行"
            ],
            [
              "アーキテクチャ",
              "信頼レベルの異なるコンテンツの分離処理",
              "外部コンテンツを別のLLM呼び出しで要約後、メインLLMに渡す「二重処理」パターン"
            ]
          ]
        },
        {
          "type": "codeBlock",
          "language": "python",
          "title": "Guardrails AI出力バリデーション",
          "filename": "output_validation.py",
          "code": "from guardrails import Guard\nfrom guardrails.hub import DetectPII, ToxicLanguage, RestrictToTopic\n\nguard = Guard().use_many(\n    DetectPII(\n        pii_entities=[\"EMAIL_ADDRESS\", \"PHONE_NUMBER\", \"PERSON\",\n                      \"CREDIT_CARD\", \"JP_MY_NUMBER\"],\n        on_fail=\"fix\"  # 検出時にマスキング\n    ),\n    ToxicLanguage(\n        threshold=0.8,\n        on_fail=\"reask\"  # 有害コンテンツ検出時にLLMに再生成を依頼\n    ),\n    RestrictToTopic(\n        valid_topics=[\"技術サポート\", \"製品情報\"],\n        invalid_topics=[\"政治\", \"宗教\", \"競合他社の批判\"],\n        on_fail=\"filter\"\n    )\n)\n\n# ガード付きLLM呼び出し\nresult = guard(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": user_input}]\n)",
          "caption": "出力側でPII、有害コンテンツ、トピック逸脱を自動検出・修正"
        },
        {
          "type": "table",
          "caption": "多層ガードレール設計",
          "headers": [
            "層",
            "コンポーネント",
            "目的",
            "ブロック時の挙動"
          ],
          "rows": [
            [
              "入力側",
              "Prompt分類器 / ブロックリスト / PII検出",
              "攻撃プロンプトの検出・PII除去",
              "ユーザーにエラーメッセージを返却。ログに記録"
            ],
            [
              "処理層",
              "システムプロンプト保護 / コンテキスト分離",
              "インジェクション耐性の向上",
              "LLMが防御プロンプトに従い安全な応答を生成"
            ],
            [
              "出力側",
              "有害コンテンツ検出 / PII再検出 / スキーマ検証",
              "不適切出力のフィルタリング",
              "マスキング / 再生成 / フォールバック応答"
            ],
            [
              "フィードバック",
              "誤検知/見逃しの報告 → ポリシー更新",
              "検出精度の継続的改善",
              "モデル再学習 / ルール更新"
            ]
          ]
        },
        {
          "type": "table",
          "caption": "Red Teamingツール",
          "headers": [
            "テスト手法",
            "ツール",
            "対象"
          ],
          "rows": [
            [
              "自動Prompt Injectionテスト",
              "Garak (NVIDIA), PyRIT (Microsoft)",
              "既知の攻撃パターンの網羅的テスト"
            ],
            [
              "Jailbreak耐性テスト",
              "HarmBench, JailbreakBench",
              "安全フィルタの回避可能性を評価"
            ],
            [
              "情報漏洩テスト",
              "カスタムスクリプト + LLMプロービング",
              "システムプロンプト・学習データの抽出可能性"
            ],
            [
              "ツール悪用テスト",
              "手動テスト + 自動化スクリプト",
              "Function Calling / MCPを経由した権限昇格"
            ]
          ]
        },
        {
          "type": "codeBlock",
          "language": "bash",
          "title": "Garak自動テストコマンド",
          "filename": "run_garak.sh",
          "code": "# Garak (NVIDIA) を用いた自動Prompt Injectionテスト\ngarak --model_type openai \\\n      --model_name gpt-4o \\\n      --probes promptinject,dan,encoding \\\n      --generations 10 \\\n      --report_prefix llm_security_audit",
          "caption": "CI/CDパイプラインに組み込み、定期的な自動テストを実施"
        },
        {
          "type": "infraDiagram",
          "variant": "dataflow",
          "title": "プロンプトセキュリティ多層防御",
          "caption": "入力→処理→出力→フィードバックの4段階フロー",
          "stages": [
            {
              "label": "入力側ガードレール",
              "color": "#DBEAFE",
              "items": [
                "ブロックリスト",
                "PII検出器 (Presidio/GiNZA)",
                "Prompt Injection分類器 (Lakera/NeMo)",
                "検出結果判定 → ブロック or 通過"
              ]
            },
            {
              "label": "LLM処理層",
              "color": "#D1FAE5",
              "items": [
                "システムプロンプト保護",
                "コンテキスト分離",
                "LLM推論実行"
              ]
            },
            {
              "label": "出力側ガードレール",
              "color": "#EDE9FE",
              "items": [
                "有害コンテンツ検出",
                "PII再検出",
                "構造化バリデーション",
                "検証結果 → 安全/要修正/ブロック"
              ]
            },
            {
              "label": "フィードバックループ",
              "color": "#FEF3C7",
              "items": [
                "誤検知レポート収集",
                "分析エンジン",
                "ポリシー・ルール自動更新"
              ]
            }
          ]
        },
        {
          "type": "subsection",
          "title": "パターン別推奨構成",
          "blocks": [
            {
              "type": "list",
              "ordered": false,
              "items": [
                "**パターンA（API直接利用）**: アプリケーションコード内でGuardrails AI / NeMo Guardrailsを統合。定期的なGarakによる自動テストをCI/CDに組み込む",
                "**パターンB（ゲートウェイ経由）**: ゲートウェイに入出力ガードレールを一元的に配置。Lakera Guard等の専用サービスをインラインで統合。集中ログによる攻撃パターン分析",
                "**パターンC（プライベートホスティング）**: 推論サーバー前段にガードレールプロキシを配置。NeMo Guardrailsを同一クラスタにデプロイ。モデル自体のファインチューニングによる安全性向上との組み合わせ"
              ]
            }
          ]
        },
        {
          "type": "checklist",
          "categories": [
            {
              "name": "プロンプトセキュリティチェックリスト",
              "items": [
                "入力側ガードレール（分類器 + ブロックリスト + PII検出）が実装されている",
                "出力側ガードレール（有害コンテンツ検出 + PII再検出 + スキーマ検証）が実装されている",
                "システムプロンプトとユーザー入力がデリミタで明確に分離されている",
                "間接的Prompt Injection対策（外部コンテンツの分離処理）が実装されている",
                "ツール利用（Function Calling / MCP）の結果が検証後に実行されている",
                "Garak / PyRIT等による定期的なレッドチームテストが実施されている",
                "攻撃検出のログとアラートが適切に設定されている",
                "フィードバックループによる検出精度の継続的改善が運用されている"
              ]
            }
          ]
        },
        {
          "type": "reactFlowDiagram",
          "diagramId": "prompt-defense"
        }
      ]
    },
    {
      "id": "security-compliance",
      "title": "コンプライアンス・監査",
      "description": "規制対応と監査ログ基盤の構築",
      "blocks": [
        {
          "type": "text",
          "content": "LLMの利用は多くの規制要件に影響を及ぼします。EU AI Act（2024年発効）によるリスクベースの規制、GDPRにおけるAIによるデータ処理の適法性、日本の個人情報保護法における要配慮個人情報の取り扱い、金融業界のFISC安全対策基準、医療分野の3省2ガイドライン等、業界・地域に応じた多様な規制への対応が求められます。さらに、LLMの出力は非決定的であるため、{{audit-log}}による完全な監査証跡の確保が不可欠です。"
        },
        {
          "type": "list",
          "ordered": false,
          "items": [
            "**完全な監査証跡**: すべてのLLMインタラクション（プロンプト・レスポンス・メタデータ）を記録する",
            "**最小保持原則**: 規制要件を満たす最小限の期間でログを保持し、不要になったデータは確実に削除する",
            "**検索可能性**: 監査要求に対し、迅速にログを検索・提出できる基盤を構築する",
            "**自動エンフォースメント**: ポリシー違反を手動監視ではなく、{{opa}}による自動検出・ブロック"
          ]
        },
        {
          "type": "table",
          "caption": "監査ログ3レベル設計",
          "headers": [
            "ログレベル",
            "記録内容",
            "保持期間",
            "ストレージ",
            "コスト感"
          ],
          "rows": [
            [
              "Level 1: メタデータ",
              "タイムスタンプ、ユーザーID、モデル名、トークン数、レイテンシ",
              "3年",
              "構造化DB (DynamoDB/BigQuery)",
              "低"
            ],
            [
              "Level 2: ハッシュ",
              "Level 1 + プロンプト/レスポンスのSHA-256ハッシュ",
              "1年",
              "構造化DB",
              "低"
            ],
            [
              "Level 3: 全文",
              "Level 1 + プロンプト/レスポンスの全文（暗号化）",
              "90日〜1年",
              "S3 (KMS暗号化) / BigQuery",
              "高"
            ]
          ]
        },
        {
          "type": "codeBlock",
          "language": "json",
          "title": "監査ログスキーマ例",
          "filename": "audit-log-schema.json",
          "code": "{\n  \"timestamp\": \"2026-02-10T09:30:00Z\",\n  \"request_id\": \"req_abc123\",\n  \"user_id\": \"user@company.com\",\n  \"user_role\": \"developer\",\n  \"model\": \"claude-sonnet-4-5\",\n  \"provider\": \"anthropic\",\n  \"action\": \"chat.completions\",\n  \"input_tokens\": 1500,\n  \"output_tokens\": 800,\n  \"latency_ms\": 2340,\n  \"status\": \"success\",\n  \"data_classification\": \"internal\",\n  \"dlp_findings\": [],\n  \"prompt_hash\": \"sha256:a1b2c3...\",\n  \"response_hash\": \"sha256:d4e5f6...\",\n  \"source_ip\": \"10.0.1.50\",\n  \"tools_used\": [\"code_interpreter\"],\n  \"guardrail_triggers\": []\n}",
          "caption": "Level 2ログの例。全文記録はLevel 3で暗号化保管"
        },
        {
          "type": "table",
          "caption": "規制対応マトリクス",
          "headers": [
            "規制",
            "主な要件",
            "LLMへの影響",
            "対応策"
          ],
          "rows": [
            [
              "GDPR",
              "データ主体の権利（アクセス権、削除権、説明権）",
              "プロンプト内個人データの処理根拠、出力の説明可能性",
              "PII匿名化 / DPA締結 / 自動意思決定への同意取得"
            ],
            [
              "個人情報保護法",
              "要配慮個人情報の取扱い、越境移転規制",
              "LLM APIへの要配慮個人情報の送信制限",
              "データ分類によるLLM利用制限 / 国内リージョン利用"
            ],
            [
              "FISC安全対策基準",
              "金融機関のIT利用に関する安全対策",
              "外部クラウドサービスの利用基準",
              "パターンC採用 / データレジデンシー確保 / 定期監査"
            ],
            [
              "3省2ガイドライン",
              "医療情報の適切な管理",
              "患者データのLLM処理に関する制約",
              "匿名化の徹底 / 国内DC利用 / ログ長期保持"
            ],
            [
              "HIPAA",
              "Protected Health Information (PHI) の保護",
              "PHIをLLMに送信する際の制約",
              "BAA締結 / PHI暗号化 / 監査ログの6年保持"
            ]
          ]
        },
        {
          "type": "table",
          "caption": "プロバイダー別データレジデンシー",
          "headers": [
            "プロバイダー",
            "日本リージョン対応",
            "データ処理の保証"
          ],
          "rows": [
            [
              "AWS Bedrock",
              "東京リージョン (ap-northeast-1)",
              "リクエスト/レスポンスはリージョン内で処理。学習には使用しない"
            ],
            [
              "Azure OpenAI",
              "Japan East",
              "データはデプロイリージョン内で処理。Abuse Monitoringは無効化可能（申請制）"
            ],
            [
              "GCP Vertex AI",
              "asia-northeast1",
              "VPC-SC + データロケーションポリシーで制御"
            ],
            [
              "OpenAI API (直接)",
              "リージョン指定不可",
              "ZDRポリシーあり。Enterprise契約で追加保証"
            ],
            [
              "Anthropic API (直接)",
              "リージョン指定不可（AWS/GCP経由で対応可）",
              "Commercial Terms: 入出力データを学習に使用しない"
            ]
          ]
        },
        {
          "type": "codeBlock",
          "language": "yaml",
          "title": "OPA Gatekeeperポリシーエンフォースメント",
          "filename": "llm-usage-policy.yaml",
          "code": "apiVersion: constraints.gatekeeper.sh/v1beta1\nkind: LLMUsagePolicy\nmetadata:\n  name: restrict-confidential-data\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"llm.company.com\"]\n        kinds: [\"LLMRequest\"]\n  parameters:\n    blockedClassifications: [\"restricted\"]\n    requiredDLPCheck: true\n    maxTokensPerRequest: 8000\n    allowedModels:\n      - \"claude-sonnet-4-5\"\n      - \"gpt-4o\"\n    requiredApprovals:\n      confidential: [\"team-lead\"]\n      restricted: [\"ciso\"]",
          "caption": "Kubernetes環境でのLLM利用ポリシーを宣言的に定義・自動適用"
        },
        {
          "type": "infraDiagram",
          "variant": "dataflow",
          "title": "監査・コンプライアンス基盤",
          "caption": "ログ収集からリアルタイム異常検知、監査エクスポートまでの5段階パイプライン",
          "stages": [
            {
              "label": "ログソース",
              "color": "#DBEAFE",
              "items": [
                "LLMゲートウェイログ",
                "DLPエンジンログ",
                "認証/認可ログ",
                "推論サーバーログ"
              ]
            },
            {
              "label": "ログ収集パイプライン",
              "color": "#D1FAE5",
              "items": [
                "Fluentd / Vector（集約・正規化・PII再マスキング）",
                "Apache Kafka（バッファリング・順序保証）"
              ]
            },
            {
              "label": "リアルタイム処理",
              "color": "#FEF3C7",
              "items": [
                "ストリーム処理 (Flink / Kinesis Analytics)",
                "異常検知エンジン",
                "アラート通知 (PagerDuty / Slack)"
              ]
            },
            {
              "label": "ストレージ層",
              "color": "#EDE9FE",
              "items": [
                "Hot: OpenSearch (30日)",
                "Warm: S3 Standard (1年)",
                "Cold: S3 Glacier (3年+)"
              ]
            },
            {
              "label": "分析・可視化",
              "color": "#FCE7F3",
              "items": [
                "Grafana ダッシュボード",
                "監査エクスポート"
              ]
            }
          ]
        },
        {
          "type": "subsection",
          "title": "パターン別推奨構成",
          "blocks": [
            {
              "type": "list",
              "ordered": false,
              "items": [
                "**パターンA（API直接利用）**: アプリケーション側でLevel 1+2ログを記録。CloudWatch Logs等に集約。プロバイダーのデータ利用ポリシーとDPA/BAA締結を確認",
                "**パターンB（ゲートウェイ経由）**: ゲートウェイでLevel 3（全文）ログを一元取得。S3 + KMS暗号化で保管しOpenSearchで検索可能に。リアルタイム異常検知パイプライン連携",
                "**パターンC（プライベートホスティング）**: 全ログをオンプレミスに保管し外部持ち出しを禁止。WORM（Write Once Read Many）ストレージで改ざん防止。ハッシュチェーンで完全性保証"
              ]
            }
          ]
        },
        {
          "type": "checklist",
          "categories": [
            {
              "name": "コンプライアンスチェックリスト",
              "items": [
                "全LLMリクエスト/レスポンスの監査ログが取得・保管されている",
                "ログのストレージ暗号化（at rest / in transit）が実装されている",
                "ログの保持期間が規制要件に基づいて設定されている",
                "監査ログの検索・エクスポート機能が実装されている",
                "対象規制（GDPR / 個人情報保護法 / 業界固有規制）への対応状況が文書化されている",
                "APIプロバイダーとのDPA/BAA等の契約が締結されている",
                "データレジデンシー要件を満たすリージョン構成が確認されている",
                "利用ポリシー違反の自動検出・ブロック機構が実装されている",
                "リアルタイム異常検知とアラート通知が稼働している"
              ]
            }
          ]
        },
        {
          "type": "reactFlowDiagram",
          "diagramId": "audit-pipeline"
        }
      ]
    },
    {
      "id": "security-supply-chain",
      "title": "サプライチェーンセキュリティ",
      "description": "モデル・プラグイン・ツールの信頼性検証",
      "blocks": [
        {
          "type": "text",
          "content": "LLMサプライチェーンは、モデルプロバイダー・ホスティング基盤・サードパーティプラグイン/ツール・ファインチューニングデータセットなど、複数の信頼関係に依存します。Hugging Face上のマルウェア入りモデルの発見や、悪意のあるMCPサーバーを通じた攻撃の報告など、LLMサプライチェーンのリスクは現実の脅威です。{{sbom}}の管理と{{cosign}}による署名検証が、包括的なサプライチェーン保護の基盤となります。"
        },
        {
          "type": "list",
          "ordered": false,
          "items": [
            "**信頼の検証**: すべてのサプライチェーンコンポーネントの信頼性を検証し、暗黙の信頼を排除する",
            "**完全性の保証**: モデルファイル・設定・依存関係の改ざんを検出する仕組みを構築する",
            "**最小権限**: サードパーティプラグインやツールに対し、必要最小限の権限のみを付与する",
            "**継続的評価**: モデルアップデートやツール変更時に{{red-teaming}}によるセキュリティ回帰テストを実施する"
          ]
        },
        {
          "type": "table",
          "caption": "プロバイダー信頼性評価（6カテゴリ）",
          "headers": [
            "評価カテゴリ",
            "確認項目",
            "推奨基準"
          ],
          "rows": [
            [
              "セキュリティ認証",
              "SOC 2 Type II、ISO 27001、CSA STAR",
              "SOC 2 Type II + ISO 27001の両方を保持"
            ],
            [
              "データ処理",
              "入出力データの学習利用有無、保持期間、暗号化",
              "学習不使用の明示的保証、AES-256暗号化、30日以内の自動削除"
            ],
            [
              "データレジデンシー",
              "処理リージョンの選択可能性、データ移転の制御",
              "日本リージョン対応、越境移転の明示的同意メカニズム"
            ],
            [
              "インシデント対応",
              "通知SLA、インシデントレスポンスプロセス",
              "72時間以内の通知、専任セキュリティチームの存在"
            ],
            [
              "契約・法的",
              "DPA / BAA / 利用規約のレビュー",
              "責任範囲の明確化、補償条項、準拠法"
            ],
            [
              "可用性",
              "SLA、障害時のフォールバック",
              "99.9%以上のSLA、マルチリージョン対応"
            ]
          ]
        },
        {
          "type": "codeBlock",
          "language": "bash",
          "title": "モデル整合性検証パイプライン",
          "filename": "verify_model.sh",
          "code": "#!/bin/bash\n# 1. モデルダウンロード時のチェックサム検証\nMODEL_URL=\"https://huggingface.co/org/model/resolve/main/model.safetensors\"\nEXPECTED_SHA256=\"a1b2c3d4e5f6...\"\n\nwget -O model.safetensors \"$MODEL_URL\"\nACTUAL_SHA256=$(sha256sum model.safetensors | awk '{print $1}')\n\nif [ \"$ACTUAL_SHA256\" != \"$EXPECTED_SHA256\" ]; then\n    echo \"ERROR: Model integrity check failed!\"\n    exit 1\nfi\n\n# 2. Sigstore/Cosign によるモデル署名検証\ncosign verify-blob \\\n  --signature model.safetensors.sig \\\n  --certificate model.safetensors.cert \\\n  model.safetensors\n\n# 3. SBOM (Software Bill of Materials) の生成\npython generate_model_sbom.py \\\n  --model-path ./model.safetensors \\\n  --output model-sbom.spdx.json \\\n  --format spdx",
          "caption": "チェックサム、Cosign署名、SBOM生成の3段階検証パイプライン"
        },
        {
          "type": "highlight",
          "variant": "warning",
          "title": "safetensorsフォーマットの推奨",
          "content": "Hugging FaceのモデルファイルにはPickle形式（.bin / .pt）とsafetensors形式があります。Pickle形式は任意のPythonコード実行が可能であり、悪意のあるモデルファイルによるRCE（Remote Code Execution）のリスクがあります。プライベートデプロイでは必ずsafetensorsを使用してください。"
        },
        {
          "type": "table",
          "caption": "MCP/プラグインリスク評価マトリクス",
          "headers": [
            "評価項目",
            "リスク: 低",
            "リスク: 中",
            "リスク: 高"
          ],
          "rows": [
            [
              "ソースコード",
              "OSS、監査済み",
              "OSS、未監査",
              "クローズドソース"
            ],
            [
              "権限要求",
              "読み取りのみ",
              "特定リソースへの書き込み",
              "広範な書き込み/実行権限"
            ],
            [
              "ネットワーク通信",
              "通信なし（ローカル処理のみ）",
              "既知APIへの制限的通信",
              "任意のエンドポイントへの通信"
            ],
            [
              "データアクセス",
              "公開データのみ",
              "社内データの読み取り",
              "機密データの読み書き"
            ],
            [
              "メンテナンス",
              "活発なメンテナンス、定期セキュリティアップデート",
              "定期的なアップデート",
              "メンテナンス不明 / 放置"
            ]
          ]
        },
        {
          "type": "codeBlock",
          "language": "yaml",
          "title": "MCPサーバーセキュリティCI/CD",
          "filename": "mcp-security-check.yaml",
          "code": "mcp_security_check:\n  steps:\n    - name: Static Analysis\n      run: |\n        # 依存関係の脆弱性スキャン\n        npm audit --json > audit-report.json\n        # または\n        pip-audit --format json -o audit-report.json\n\n    - name: Permission Analysis\n      run: |\n        python analyze_mcp_permissions.py \\\n          --manifest mcp-server/manifest.json \\\n          --policy company-mcp-policy.yaml\n\n    - name: Network Analysis\n      run: |\n        python analyze_network_calls.py \\\n          --source mcp-server/ \\\n          --allowed-domains allowed-domains.txt\n\n    - name: Sandbox Test\n      run: |\n        docker run --network=none --read-only \\\n          mcp-server-test:latest",
          "caption": "MCPサーバーの依存関係・権限・ネットワーク・サンドボックスを自動検証"
        },
        {
          "type": "subsection",
          "title": "パターン別推奨構成",
          "blocks": [
            {
              "type": "list",
              "ordered": false,
              "items": [
                "**パターンA（API直接利用）**: プロバイダーの認証・ポリシーの定期レビュー。サードパーティツール/プラグインの利用承認プロセスの確立。APIバージョン固定とアップデート時のテスト",
                "**パターンB（ゲートウェイ経由）**: ゲートウェイでのプロバイダー切り替え対応（マルチプロバイダー戦略）。プラグイン/MCPサーバーのサンドボックス実行。モデルバージョン管理とカナリアデプロイ",
                "**パターンC（プライベートホスティング）**: モデルファイルのチェックサム・署名検証を必須化。{{sbom}}の生成・管理。エアギャップ環境でのモデルデプロイパイプライン。依存ライブラリの定期的な脆弱性スキャン"
              ]
            }
          ]
        },
        {
          "type": "checklist",
          "categories": [
            {
              "name": "サプライチェーンチェックリスト",
              "items": [
                "モデルプロバイダーの信頼性評価が実施・文書化されている",
                "プロバイダーとのDPA / BAA / セキュリティ条項が締結されている",
                "モデルファイルの整合性検証（チェックサム / 署名）が実装されている",
                "safetensors形式が使用されている（Pickleモデルの使用を禁止）",
                "SBOM（Software Bill of Materials）が生成・管理されている",
                "サードパーティプラグイン / MCPサーバーのリスク評価プロセスが確立されている",
                "プラグインのサンドボックス実行環境が構築されている",
                "モデルアップデート時のセキュリティ回帰テストがCI/CDに組み込まれている",
                "マルチプロバイダー戦略（プロバイダー障害時のフォールバック）が検討されている"
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "cost-optimization",
      "title": "コスト最適化の実装",
      "description": "LLM利用コストを50-90%削減する実践的手法",
      "blocks": [
        {
          "type": "text",
          "content": "LLMのコスト最適化は{{finops}}の観点から体系的に取り組む必要があります。{{prompt-caching}}、{{semantic-caching}}、{{batch-api}}、{{smart-routing}}の組み合わせにより、大幅なコスト削減が現実的に達成可能です。"
        },
        {
          "type": "stats",
          "items": [
            {
              "label": "プロンプトキャッシュ",
              "value": "最大90%削減",
              "trend": "up"
            },
            {
              "label": "セマンティックキャッシュ",
              "value": "50%+削減",
              "trend": "up"
            },
            {
              "label": "バッチAPI",
              "value": "50%削減",
              "trend": "up"
            },
            {
              "label": "スマートルーティング",
              "value": "30-60%削減",
              "trend": "up"
            }
          ]
        },
        {
          "type": "stepGuide",
          "title": "コスト最適化ステップ",
          "steps": [
            {
              "label": "Step 1",
              "title": "プロンプトキャッシングの有効化",
              "description": "Anthropic APIのプロンプトキャッシング機能を有効化し、長いシステムプロンプトのプレフィックス部分をキャッシュします。入力トークンコストを最大90%削減できます。",
              "duration": "2-4時間",
              "difficulty": "easy",
              "blocks": [
                {
                  "type": "codeBlock",
                  "language": "python",
                  "title": "プロンプトキャッシングの実装",
                  "filename": "cached_call.py",
                  "code": "import anthropic\n\nclient = anthropic.Anthropic()\n\n# キャッシュ対象のシステムプロンプト（1024トークン以上）\nSYSTEM_PROMPT = \"\"\"あなたは金融アドバイザーです...\n(長いシステムプロンプト)\"\"\"\n\nresponse = client.messages.create(\n    model=\"claude-sonnet-4-5-20250929\",\n    max_tokens=1024,\n    system=[\n        {\n            \"type\": \"text\",\n            \"text\": SYSTEM_PROMPT,\n            \"cache_control\": {\"type\": \"ephemeral\"}\n        }\n    ],\n    messages=[{\"role\": \"user\", \"content\": \"質問内容\"}],\n)\n# cache_read_input_tokens > 0 ならキャッシュヒット",
                  "caption": "cache_controlを指定するだけで自動的にキャッシュが有効化される"
                }
              ]
            },
            {
              "label": "Step 2",
              "title": "スマートルーティングの設定",
              "description": "{{smart-routing}}を設定して、簡単なタスクには軽量モデル（Claude Haiku）、複雑なタスクには高性能モデル（Claude Opus）を自動振り分けします。",
              "duration": "1-2日",
              "difficulty": "medium"
            },
            {
              "label": "Step 3",
              "title": "バッチAPIの活用",
              "description": "非リアルタイムのワークロード（分析、レポート生成、分類）を{{batch-api}}に移行し、50%のコスト削減を実現します。",
              "duration": "1-2日",
              "difficulty": "easy"
            },
            {
              "label": "Step 4",
              "title": "コストダッシュボードの構築",
              "description": "{{cost-allocation}}に基づく部門別・プロジェクト別のコストダッシュボードを構築し、予算超過のアラートを設定します。",
              "duration": "3-5日",
              "difficulty": "medium"
            }
          ]
        },
        {
          "type": "table",
          "caption": "最適化手法の効果比較",
          "headers": [
            "手法",
            "コスト削減",
            "実装難易度",
            "適用条件"
          ],
          "rows": [
            [
              "プロンプトキャッシング",
              "最大90%（入力）",
              "低",
              "長いシステムプロンプト"
            ],
            [
              "セマンティックキャッシング",
              "50%以上",
              "中",
              "類似クエリが多い"
            ],
            [
              "バッチAPI",
              "50%",
              "低",
              "リアルタイム性不要"
            ],
            [
              "スマートルーティング",
              "30-60%",
              "中",
              "タスクの複雑さが多様"
            ],
            [
              "トークン最適化",
              "20-40%",
              "低",
              "全ケース"
            ],
            [
              "リザーブドキャパシティ",
              "20-40%",
              "低",
              "安定した大量利用"
            ]
          ]
        }
      ]
    },
    {
      "id": "monitoring",
      "title": "監視・観測性の構築",
      "description": "LLM基盤のオブザーバビリティスタック",
      "blocks": [
        {
          "type": "text",
          "content": "{{observability}}はLLM基盤の安定運用に不可欠です。メトリクス・ログ・トレースの3本柱を構築し、{{sla}}に基づいたモニタリングとアラートを設定します。"
        },
        {
          "type": "infraDiagram",
          "variant": "dataflow",
          "title": "モニタリングパイプライン",
          "caption": "全てのLLMリクエストからメトリクス・ログ・トレースを収集",
          "stages": [
            {
              "label": "データソース",
              "color": "#3B82F6",
              "items": [
                "LLM Gateway",
                "Application",
                "Infrastructure"
              ]
            },
            {
              "label": "収集",
              "color": "#10B981",
              "items": [
                "OpenTelemetry",
                "Fluentd",
                "Prometheus"
              ]
            },
            {
              "label": "保存",
              "color": "#F59E0B",
              "items": [
                "Grafana Loki",
                "Prometheus TSDB",
                "Jaeger"
              ]
            },
            {
              "label": "可視化",
              "color": "#A855F7",
              "items": [
                "Grafana",
                "PagerDuty",
                "Slack"
              ]
            }
          ]
        },
        {
          "type": "stepGuide",
          "title": "モニタリング構築ステップ",
          "steps": [
            {
              "label": "Step 1",
              "title": "メトリクス収集の設定",
              "description": "Prometheusでリクエスト数、レイテンシ（P50/P95/P99）、トークン使用量、エラーレート、キャッシュヒット率を収集します。",
              "duration": "2-3日",
              "difficulty": "medium",
              "blocks": [
                {
                  "type": "codeBlock",
                  "language": "yaml",
                  "title": "Prometheus メトリクス設定",
                  "filename": "prometheus-rules.yaml",
                  "code": "groups:\n  - name: llm_metrics\n    rules:\n      - alert: HighErrorRate\n        expr: |\n          rate(llm_requests_total{status=\"error\"}[5m])\n          / rate(llm_requests_total[5m]) > 0.05\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"LLM APIエラー率が5%を超過\"\n      \n      - alert: HighLatency\n        expr: |\n          histogram_quantile(0.95, \n            rate(llm_request_duration_seconds_bucket[5m])\n          ) > 10\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"LLM P95レイテンシが10秒を超過\""
                }
              ]
            },
            {
              "label": "Step 2",
              "title": "ログ収集パイプライン",
              "description": "全LLMリクエスト/レスポンスの構造化ログを収集します。プロンプト内容はPII検出後にマスキングしてから保存します。",
              "duration": "2-3日",
              "difficulty": "medium"
            },
            {
              "label": "Step 3",
              "title": "ダッシュボードの構築",
              "description": "Grafanaで運用ダッシュボード（リアルタイムメトリクス）、コストダッシュボード（利用量・費用追跡）、SLAダッシュボード（目標vs実績）を作成します。",
              "duration": "2-3日",
              "difficulty": "easy"
            },
            {
              "label": "Step 4",
              "title": "アラートの設定",
              "description": "PagerDutyやSlackと連携し、SLA違反、エラー率閾値超過、コスト異常検知のアラートを設定します。{{incident-management}}プロセスとの統合も行います。",
              "duration": "1-2日",
              "difficulty": "easy"
            }
          ]
        },
        {
          "type": "table",
          "caption": "推奨SLI/SLO設定",
          "headers": [
            "メトリクス",
            "SLI",
            "SLO目標",
            "測定方法"
          ],
          "rows": [
            [
              "可用性",
              "成功リクエスト率",
              "99.9%",
              "5分間ウィンドウ"
            ],
            [
              "レイテンシ",
              "P95応答時間",
              "< 5秒",
              "ヒストグラム"
            ],
            [
              "エラーレート",
              "5xxエラー率",
              "< 0.1%",
              "カウンター"
            ],
            [
              "スループット",
              "RPS上限",
              "> 100 req/s",
              "レートカウンター"
            ]
          ]
        }
      ]
    },
    {
      "id": "implementation-roadmap",
      "title": "実装ロードマップ",
      "description": "段階的な導入計画とマイルストーン",
      "blocks": [
        {
          "type": "text",
          "content": "LLM基盤の構築は一度にすべてを実装するのではなく、段階的に進めることが成功の鍵です。以下の4フェーズに分けて、各フェーズで明確なROIを確認しながら進行します。"
        },
        {
          "type": "timeline",
          "phases": [
            {
              "id": "phase-1",
              "title": "Phase 1: 基盤構築",
              "duration": "Week 1-2",
              "investment": "エンジニア2名 × 2週間",
              "roi": "API利用開始",
              "items": [
                {
                  "task": "APIキー管理の整備",
                  "duration": "2日",
                  "resources": "SRE 1名",
                  "effect": "セキュアなアクセス"
                },
                {
                  "task": "SDKセットアップとサンプル実装",
                  "duration": "3日",
                  "resources": "Backend 1名",
                  "effect": "最初のAPI呼び出し"
                },
                {
                  "task": "基本ログ収集の設定",
                  "duration": "2日",
                  "resources": "SRE 1名",
                  "effect": "利用状況の可視化"
                },
                {
                  "task": "コスト追跡の開始",
                  "duration": "1日",
                  "resources": "SRE 1名",
                  "effect": "予算管理の基盤"
                }
              ]
            },
            {
              "id": "phase-2",
              "title": "Phase 2: セキュリティ強化",
              "duration": "Week 3-4",
              "investment": "エンジニア2-3名 × 2週間",
              "roi": "全社展開可能に",
              "items": [
                {
                  "task": "PII検出/マスキングの実装",
                  "duration": "5日",
                  "resources": "Security 1名",
                  "effect": "データ保護"
                },
                {
                  "task": "RBAC/SSO統合",
                  "duration": "3日",
                  "resources": "Platform 1名",
                  "effect": "アクセス制御"
                },
                {
                  "task": "監査ログの整備",
                  "duration": "2日",
                  "resources": "SRE 1名",
                  "effect": "コンプライアンス"
                },
                {
                  "task": "ガードレール設定",
                  "duration": "3日",
                  "resources": "ML Eng 1名",
                  "effect": "安全な利用"
                }
              ]
            },
            {
              "id": "phase-3",
              "title": "Phase 3: 最適化",
              "duration": "Month 2",
              "investment": "エンジニア2名 × 4週間",
              "roi": "50-70%コスト削減",
              "items": [
                {
                  "task": "プロンプトキャッシングの有効化",
                  "duration": "2日",
                  "resources": "Backend 1名",
                  "effect": "最大90%入力コスト削減"
                },
                {
                  "task": "セマンティックキャッシュの構築",
                  "duration": "5日",
                  "resources": "ML Eng 1名",
                  "effect": "50%+コスト削減"
                },
                {
                  "task": "スマートルーティングの実装",
                  "duration": "5日",
                  "resources": "Platform 1名",
                  "effect": "30-60%コスト削減"
                },
                {
                  "task": "バッチAPI移行",
                  "duration": "3日",
                  "resources": "Backend 1名",
                  "effect": "50%バッチコスト削減"
                }
              ]
            },
            {
              "id": "phase-4",
              "title": "Phase 4: スケール",
              "duration": "Month 3+",
              "investment": "チーム3-5名 (継続)",
              "roi": "全社LLM基盤完成",
              "items": [
                {
                  "task": "Grafanaダッシュボード構築",
                  "duration": "5日",
                  "resources": "SRE 1名",
                  "effect": "運用可視化"
                },
                {
                  "task": "オートスケーリング設定",
                  "duration": "5日",
                  "resources": "SRE 1名",
                  "effect": "負荷対応"
                },
                {
                  "task": "マルチモデル戦略の展開",
                  "duration": "5日",
                  "resources": "ML Eng 1名",
                  "effect": "柔軟性向上"
                },
                {
                  "task": "FinOpsプロセスの確立",
                  "duration": "5日",
                  "resources": "Platform 1名",
                  "effect": "継続的最適化"
                }
              ]
            }
          ],
          "staffing": [
            {
              "phase": "Phase 1-2",
              "skills": "SRE、バックエンドエンジニア",
              "team": "2-3名"
            },
            {
              "phase": "Phase 3",
              "skills": "MLエンジニア、プラットフォームエンジニア",
              "team": "2名追加"
            },
            {
              "phase": "Phase 4",
              "skills": "全スキルセット + FinOps",
              "team": "3-5名チーム"
            }
          ]
        }
      ]
    },
    {
      "id": "decision-framework",
      "title": "意思決定フレームワーク",
      "description": "最適なパターンを選択するための判断基準",
      "blocks": [
        {
          "type": "text",
          "content": "以下のフローチャートとチェックリストを使用して、組織に最適なLLM基盤パターンを選定してください。"
        },
        {
          "type": "flowchart",
          "nodes": [
            {
              "id": "q1",
              "question": "月間LLM APIコストは$5,000を超えますか？",
              "yes": "q2",
              "no": "r1"
            },
            {
              "id": "r1",
              "result": "パターンA: 直接利用で開始"
            },
            {
              "id": "q2",
              "question": "DLP/PII検出の要件がありますか？",
              "yes": "q3",
              "no": "q4"
            },
            {
              "id": "q3",
              "question": "データの完全な社内保持が必須ですか？",
              "yes": "r3",
              "no": "r2"
            },
            {
              "id": "r2",
              "result": "パターンB: LLMゲートウェイを構築"
            },
            {
              "id": "r3",
              "result": "パターンC: プライベート/オンプレ構築"
            },
            {
              "id": "q4",
              "question": "5チーム以上がLLMを利用しますか？",
              "yes": "r2",
              "no": "r1"
            }
          ]
        },
        {
          "type": "text",
          "content": "セキュリティ観点での最適パターン選定には、規制要件・データ機密度・PII処理の有無・利用規模を考慮します。以下のフローチャートで推奨パターンを判定してください。"
        },
        {
          "type": "flowchart",
          "nodes": [
            {
              "id": "sq1",
              "question": "規制業界（金融・医療・防衛）ですか？",
              "yes": "sq2",
              "no": "sq3"
            },
            {
              "id": "sq2",
              "question": "データの完全な社内保持が法的に義務づけられていますか？",
              "yes": "sr3",
              "no": "sq4"
            },
            {
              "id": "sq3",
              "question": "PIIを含むデータをLLMで処理しますか？",
              "yes": "sq4",
              "no": "sq5"
            },
            {
              "id": "sq4",
              "question": "DLP/PII検出を集中管理する必要がありますか？",
              "yes": "sr2",
              "no": "sq5"
            },
            {
              "id": "sq5",
              "question": "利用規模は100名以上ですか？",
              "yes": "sr2",
              "no": "sr1"
            },
            {
              "id": "sr1",
              "result": "パターンA: API直接利用（クライアントサイドDLP）"
            },
            {
              "id": "sr2",
              "result": "パターンB: LLMゲートウェイ（集中DLP + RBAC）"
            },
            {
              "id": "sr3",
              "result": "パターンC: プライベートホスティング（完全データ統制）"
            }
          ]
        }
      ]
    },
    {
      "id": "references",
      "title": "参考リソース",
      "description": "公式ドキュメントとツール",
      "blocks": [
        {
          "type": "sources",
          "categories": [
            {
              "name": "LLM APIプロバイダー公式ドキュメント",
              "links": [
                {
                  "title": "Anthropic API ドキュメント",
                  "url": "https://docs.anthropic.com/"
                },
                {
                  "title": "Anthropic プロンプトキャッシング",
                  "url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching"
                },
                {
                  "title": "Anthropic バッチAPI",
                  "url": "https://docs.anthropic.com/en/docs/build-with-claude/message-batches"
                },
                {
                  "title": "OpenAI APIリファレンス",
                  "url": "https://platform.openai.com/docs/api-reference"
                },
                {
                  "title": "Google Gemini API",
                  "url": "https://ai.google.dev/docs"
                }
              ]
            },
            {
              "name": "ゲートウェイ・ツール",
              "links": [
                {
                  "title": "LiteLLM (OSS Gateway)",
                  "url": "https://github.com/BerriAI/litellm"
                },
                {
                  "title": "Portkey AI Gateway",
                  "url": "https://portkey.ai/"
                },
                {
                  "title": "Helicone (LLM Observability)",
                  "url": "https://www.helicone.ai/"
                },
                {
                  "title": "LangSmith (Tracing)",
                  "url": "https://www.langchain.com/langsmith"
                },
                {
                  "title": "Guardrails AI",
                  "url": "https://github.com/guardrails-ai/guardrails"
                }
              ]
            },
            {
              "name": "推論エンジン・モデルサービング",
              "links": [
                {
                  "title": "vLLM",
                  "url": "https://github.com/vllm-project/vllm"
                },
                {
                  "title": "Text Generation Inference (TGI)",
                  "url": "https://github.com/huggingface/text-generation-inference"
                },
                {
                  "title": "NVIDIA TensorRT-LLM",
                  "url": "https://github.com/NVIDIA/TensorRT-LLM"
                },
                {
                  "title": "Ollama (ローカル推論)",
                  "url": "https://ollama.com/"
                }
              ]
            },
            {
              "name": "監視・セキュリティ",
              "links": [
                {
                  "title": "OpenTelemetry",
                  "url": "https://opentelemetry.io/"
                },
                {
                  "title": "Grafana",
                  "url": "https://grafana.com/"
                },
                {
                  "title": "Prometheus",
                  "url": "https://prometheus.io/"
                },
                {
                  "title": "Microsoft Presidio (PII検出)",
                  "url": "https://github.com/microsoft/presidio"
                },
                {
                  "title": "OWASP LLM Top 10",
                  "url": "https://owasp.org/www-project-top-10-for-large-language-model-applications/"
                }
              ]
            },
            {
              "name": "セキュリティ・コンプライアンス",
              "links": [
                {
                  "title": "OWASP Top 10 for LLM Applications (2025)",
                  "url": "https://owasp.org/www-project-top-10-for-large-language-model-applications/"
                },
                {
                  "title": "NIST AI Risk Management Framework",
                  "url": "https://www.nist.gov/artificial-intelligence/executive-order-safe-secure-and-trustworthy-artificial-intelligence"
                },
                {
                  "title": "MITRE ATLAS",
                  "url": "https://atlas.mitre.org/"
                },
                {
                  "title": "Garak (NVIDIA) - LLM脆弱性スキャナー",
                  "url": "https://github.com/NVIDIA/garak"
                },
                {
                  "title": "PyRIT (Microsoft) - AI Red Teaming",
                  "url": "https://github.com/Azure/PyRIT"
                },
                {
                  "title": "Lakera Guard",
                  "url": "https://www.lakera.ai/"
                },
                {
                  "title": "NVIDIA NeMo Guardrails",
                  "url": "https://github.com/NVIDIA/NeMo-Guardrails"
                },
                {
                  "title": "HashiCorp Vault",
                  "url": "https://www.vaultproject.io/"
                },
                {
                  "title": "Open Policy Agent (OPA)",
                  "url": "https://www.openpolicyagent.org/"
                },
                {
                  "title": "Sigstore / Cosign",
                  "url": "https://www.sigstore.dev/"
                }
              ]
            }
          ]
        },
        {
          "type": "highlight",
          "variant": "info",
          "title": "免責事項",
          "content": "本ガイドの情報は2026年2月時点のものです。LLM業界は急速に変化しているため、実装前に各ツール・サービスの最新ドキュメントを確認してください。"
        }
      ]
    }
  ]
}